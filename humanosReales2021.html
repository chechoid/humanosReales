<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>People Analytics con R</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <link href="libs/vis/vis.css" rel="stylesheet" />
    <script src="libs/vis/vis.min.js"></script>
    <script src="libs/visNetwork-binding/visNetwork.js"></script>
    <link href="libs/wordcloud2/wordcloud.css" rel="stylesheet" />
    <script src="libs/wordcloud2/wordcloud2-all.js"></script>
    <script src="libs/wordcloud2/hover.js"></script>
    <script src="libs/wordcloud2-binding/wordcloud2.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# People Analytics con R
## An√°lisis Predictivo de Attrition
### <svg viewBox="0 0 448 512" style="position:relative;display:inline-block;top:.1em;fill:white;height:1.5em;" xmlns="http://www.w3.org/2000/svg">
<path d="M323.56 51.2c-20.8 19.3-39.58 39.59-56.22 59.97C240.08 73.62 206.28 35.53 168 0 69.74 91.17 0 209.96 0 281.6 0 408.85 100.29 512 224 512s224-103.15 224-230.4c0-53.27-51.98-163.14-124.44-230.4zm-19.47 340.65C282.43 407.01 255.72 416 226.86 416 154.71 416 96 368.26 96 290.75c0-38.61 24.31-72.63 72.79-130.75 6.93 7.98 98.83 125.34 98.83 125.34l58.63-66.88c4.14 6.85 7.91 13.55 11.27 19.97 27.35 52.19 15.81 118.97-33.43 153.42z"></path>
</svg>
<a href="https://www.linkedin.com/in/sergiogarciamora/">Sergio Garcia Mora</a><br><br><svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:white;height:1.5em;" xmlns="http://www.w3.org/2000/svg"> <path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 448c-110.3 0-200-89.7-200-200S137.7 56 248 56s200 89.7 200 200-89.7 200-200 200zm117.8-146.4c-10.2-8.5-25.3-7.1-33.8 3.1-20.8 25-51.5 39.4-84 39.4s-63.2-14.3-84-39.4c-8.5-10.2-23.7-11.5-33.8-3.1-10.2 8.5-11.5 23.6-3.1 33.8 30 36 74.1 56.6 120.9 56.6s90.9-20.6 120.9-56.6c8.5-10.2 7.1-25.3-3.1-33.8zM168 240c17.7 0 32-14.3 32-32s-14.3-32-32-32-32 14.3-32 32 14.3 32 32 32zm160-60c-25.7 0-55.9 16.9-59.9 42.1-1.7 11.2 11.5 18.2 19.8 10.8l9.5-8.5c14.8-13.2 46.2-13.2 61 0l9.5 8.5c8.5 7.4 21.6.3 19.8-10.8-3.8-25.2-34-42.1-59.7-42.1z"></path></svg> <a href="https://data-4hr.com">Data 4HR</a>
### HR Bootcamp - Humanos Reales

---






# Sergio Garc√≠a Mora

.left-column[
&lt;img src="Archivos/eu.jpg" /&gt;
]

.right-column[
* ### ü§ì HR Nerd
* üí™ Lic. en Relaciones del Trabajo con formaci√≥n en Data Mining
* ‚úàÔ∏è Fundador de [Data 4HR](https://data-4hr.com/)
* üíπ SME People Analytics en [Data IQ](https://dataiq.com.ar/)
* üë©‚Äçüè´ Profesor de People Analytics en ITBA
* üç∑ Fundador del [Club de R para RRHH](https://r4hr.club)
* üëë Meme Manager en varias comunidades

]
---

.pull-left[
En alguna √©poca sol√≠a bromear con que era parecido a [Nicol√°s del Ca√±o](https://www.xn--nicolasdelcao-tkb.com.ar/)
&lt;br&gt;
&lt;img src="Archivos/knn_checho.png" width="60%" /&gt;
]

--

.pull-right[
Pero los datos dicen otra cosa...
&lt;img src="humanosReales2021_files/figure-html/knn-1.png" width="504" /&gt;

]
---
class: inverse center middle
# ¬øQu√© es R y para qu√© sirve en RRHH?


---
# ¬øQu√© es R?

**R** es un lenguaje de c√≥digo abierto, que se hizo conocido inicialmente como un lenguaje de an√°lisis estad√≠stico.

--

Hoy en d√≠a, y gracias a la comunidad de desarrolladores quienes expandieron sus capacidades, se puede usar R para muchas cosas m√°s.

--

Los principales usuarios de R vienen de muchas profesiones que mayormente no est√° relacionada con las Ciencias de la Computaci√≥n, de ah√≠ que se prioriza la usabilidad del c√≥digo, la reproducibilidad de los proyectos, a veces en desmedro de la performance, pero con una diversidad de paquetes y aplicaciones que hacen m√°s simple la curva de aprendizaje.

--

En R pod√©s trabajar con cualquier tipo de datos, y hacer todo tipo de an√°lisis que se te ocurra.

---
## An√°lisis de Clusters

.pull-left[
Los an√°lisis de clusters son √∫tiles para encontrar grupos (clusters) entre los datos.
&lt;img src="humanosReales2021_files/figure-html/cluster1-1.png" width="80%" /&gt;

]

.pull-right[
&lt;img src="humanosReales2021_files/figure-html/cluster2-1.png" width="504" /&gt;

]

---
## Organizational Network Analysis

.pull-left[
<div id="htmlwidget-6d3ee12599ed41686b28" style="width:504px;height:504px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-6d3ee12599ed41686b28">{"x":{"nodes":{"id":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264],"label":["Javier Calzolari","Pablo Senra","Sergio E. Garcia Mora","Erik van Vulpen","Facundo Iannello","Marina Ca√±izo","Eduardo Terr√≥n G√≥mez","Daniela Alonso","Ariel Felsztyna","Micaela M. Kulesz, PhD","Santiago Candia","Carsten Kraus","Yael Epstein","Vanina Petillo","Miranda Chab","Mar√≠a Bel√©n Karamanukian","Macarena Est√©vez - Socia Deloitte","Daniela Clavel","Gabriela Gisele P√©rez","Andrea Cesar","Chiara Usuardi","Carlos Matias Bavoleo","Mar√≠a Florencia N√°poli","Jose Istillarte","H√©ctor Vega","Maximiliano Eggers","Natalia Gudalewicz","Alejandro Rodriguez I.","Gustavo Bulgach","Alejandro Tejada Borges","Carolina Coronado","Fernando Morente Cadenas de Llano","Noeli Daniela Rossi","Edwin Andres Sorza Gonzalez","Nataly Escobari","Luis Alfonso Gomez Zu√±iga","Gerardo Floridia","Nahuel Rodriguez Araujo","David Ruiz","Edgardo Lugo","Kenny Rodriguez Olier","Renzo Enrique Palomino T√°vara","Fernando Flores","Victor Rumay","Marino Pern√≠a G.","Alan Rosenfeld","Kevin Vargas","Ail√©n Rojas","Mariano d'Almeida","Hernan Herrera Albelo","Guadalupe Alvarez Mulleady","Dami√°n Barbero","Emanuel Saavedra","Gloria Caterina Ruschner","Eduardo Illiano","Jaime O'Conor","Mathias Longo","Federico Piacente","Cristian Jakubowski","Mauricio Anderson","Mauro Garc√≠a","Mar√≠a Florencia Rossi","Johanna Dragone","Ramiro Savoie","Carolina Ielapi","Gilmar Argote","Agustina Ormart","Alejandro Eloy La Moglie","Rodrigo Pantoja Navajas","Jorge Vidaurre","Javier Gurevich","Christian Cerrella","Ariel Camargo","Diego Mart√≠n Vacarezza","Mirian Faig","Marcelo Piattini Velthuis","Federico Vidal","Joan Manuel Perez Meiss","Pablo A. Guzzi","Martin Carames Abente","Matias Juan Leive","Fabrisio Foscarino","Ramiro Fern√°ndez","Pablo Avenali","Ezequiel Gutt","Christian Grunblatt","Romina Prez","Roberto Panai","Rolando Guti√©rrez Cort√©s","Ignacio Tom√°s Bullrich","Blanca Monreal","Agustin Markovic","Daniel Rivera Escobar","Iv√°n Guerrero Mel√©ndez","Jorge Brian Alarc√≥n Flores","Fernando L√≥pez Gil","Lic. Ana Belen Gonzalez Arguello","Leonardo Ball√≥n","Marcela Huerfano","Ismael G√≥mez Schmidt","Juan Francisco Mu√±oz","Ariel Fleiderman","Anita Quevedo","Tom√°s Marcos","Jorge Maria Ortiz Claverol","Romain Martin","Javier Orraca","Rafael Zambrano","Luciano Borgoglio","Mariana Hariri","Yolanda Barrull","Alejandro S√°nchez Rodr√≠guez","Ignacio Lecha Val","Luis Serra D√≠az-Cano","Jean (JP) Philius","Alexandru Gotoi","Emmanuel Mart√≠n Garnica","Almudena L√≥pez-Cediel Verd√∫","Eloy Elig√≥n","Augusto Gentile","Andr√©s Paredes","Francisco J. Rodr√≠guez","Jayshween Shiron Kumar","Andreas Kyprianou","Daniel Lacunza","Mehul Pandya","Info Data 4HR","M.Angeles Alba Garc√≠a de la Camacha","Gisele Cabrera","Manish Anand","Barbara Anania","Andres Diaz Devia","Dan Moorehead","Valentin Veronesi","Rodrigo Le√≥n Tovi","Gal Mozes","Hamza MADMOUNE","Luis Andr√©s Mart√≠nez Peraza","Daniela Garay","Desalina (Alina) Guarise, MPA, PHR","Gabriela Bouret","juan jose iguaran fernandez","Pablo G√≥mez Ase","Federico Abud","Hern√°n Escudero","Abhinav Meesa","Maria Nolazco Masson","Daniel Garcia Teba","Federico Ezequiel Torres","Olmo Barragan","Federico Ariel Mendez","Eduardo Valencia","Pablo Garriga Su√°rez","Daiana Emili","Karina Bartolome","Mariano Alonso","Nicol√°s Morales Galaz","Sergio Raja","Chris Coleman","Chris Wilpert","Martin Juiz","Claudio Mac-Lean","Viviana Vald√©s","Monica Patricia Pineda Vargas","Mar√≠a Emilia Charnelli","Littal Shemer Haim (◊ú◊ô◊ò◊ú ◊©◊û◊® ◊ó◊ô◊ô◊ù)","Georgina Ricci","Federico Schmidt","Mat√≠as Conde","Mar√≠a Jes√∫s Beliz√≥n Cebada, Ph.D.","Giovanna Constant","Edgar Leandro Jimenez","Diego Antonio Hern√°ndez Ronquillo","Jos√© De Souza","Praveen Viswam, GPHR","Paulina Verasay","Keith McNulty","Muge Bakkaloglu, PMP¬Æ","Mike West","Ana Rita Almada","Martin Andres Minnoni","An Rycek","Ewuard Avila Silva, Msc.","Jorge Esteban Salde√±a","Sofia Rovito","Gaurav Guliani","Pablo Martin Karg","Sofia Fasce","Sebasti√°n Lombra√±a","Federico Costa","Manuel Villalonga","Dante Maino","Eliana Moccia","NAZARENO MEDRANO","Diego Ignacio Pe√±aloza","Ricardo Leston","Juan Agustin Vago","Sebastian Sanchez Mazza","Simon White","Walter Alejandro Bernal","Franco Ubber Scapin","German Avanzato","Matias Monja","Juan Agustin Pisano","Nexbas S.A.","Andrew Sosa","Guido Luca Oliveri","Agustin Fusaro","Wayne Lee","Eugenio Molina","Lambolla Mariano","Jack Dunn","Dr. Andrew Doyle","Dr. Lakshmi Keerthi, PhD","Ivanna Grone","Kanwal Safdar","Edgardo Ariel Osorio","Sjoerd van den Heuvel","Romina Medina","Gabriel Ravena","Federico Vazquez Morales","Mariano Ariel Bernardoni","Juan Mart√≠n Rom√°n","Richard Rosenow","Pablo Daniel Morinigo","Ra√∫l Mascar√≥","Victor Daniel Casas Hernandez","Ramiro Marchesini Piedra","Clarisa Castelloni","Martin Nash","Damian Ignacio Ramos","Patricia Isabel Romero","Santiago Donikian","Jonathan Nicol√°s Gimenez","Matias Rivero","Amalia Carolina Guaym√°s Canavire","Martin Maffioli","Alejandro Salevsky","Florencia Novidelsky","Fernando Croceri","Adri√°n Mart√≠n Urrutia Toledo","Alejandro Tamashiro","Nicol√°s Martins","Rodrigo Lloret","Roc√≠o Cairo Presepi","Rub√©n Flecha","Fernando Gonzalez","Pablo Tempone","Romina Elena Almada","Sergio Miller","Gabriela Plantie","Diego Juritz","Eduardo J. Azzola","Justo Ra√∫l Revilla Calle","Federico Rosenhain","Lissett Goncalves","Agust√≠n Demarchi","Guillermo Lissa","Omar Ernesto Cabrera Rosero","Marcos Feole","Gaston Liberman","Daniela Blanco","Leandro Mart√≠n R√≠os","Lucas Pogorelsky"],"color":["#DD6B06","#DD6B06","#DD6B06","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB","#2CAFBB"],"x":[-0.380198181667107,-0.716737295881704,0.485984106510756,-0.0190811813029821,-0.652828520123374,-0.7099642063213,-0.694259957288793,0.0316797943968643,-0.0541057429532188,-0.556088946898292,-0.0655859906551042,-0.763269271034276,-0.621720582967938,-0.703636306118944,-0.031498816457299,-0.713980336578253,-0.798939481257919,-0.732862029119333,-0.0630073213227397,-0.695183669445346,-0.821799499176499,0.046644714212581,0.0196273213796554,-0.617664605431393,0.00396483009912174,-0.0578059660395946,0.0446882293570812,0.0173818567464312,0.0472815266261379,-0.0328200545379105,-0.597825768225917,-0.76452839295243,-0.793037001845102,-0.686543628947452,-0.748995775057242,-0.015671252030413,-0.0307450611362442,-0.763058228095675,-0.66342837654684,-0.786475533311874,-0.829585461515418,-0.504386805395278,-0.0275098753142193,-0.612290722009401,-0.625248355082619,-0.610696997810572,-0.542349479092063,-0.0324403154163104,-0.65708879457848,-0.668516399831613,-0.735275039183454,-0.648707771429156,-0.498074077912425,-0.0393035290822938,0.0306788215934366,-0.530125414239731,-0.636485081664795,-0.627307855764186,-0.747062987492616,0.00909997561049214,-0.592022850387404,-0.825320304973812,-0.819701560367055,-0.792388898294928,-0.754669705265013,-0.56193601729167,-0.561799004773806,-0.583428582848576,0.0188597494548539,-0.586082898431392,-0.0616363550322777,-0.704870944653729,-0.683869247527316,-0.0109971673091508,-0.465873989347687,-0.579863830338671,-0.652665294753384,4.21535264882866e-05,-0.0163593979820366,-0.00455024371269741,-0.202266937449363,-0.746646075789563,0.0283639027589655,-0.961647880010466,-0.939224600983741,-0.883601867595462,-1,0.509834005013043,0.401001453545725,0.646798705910049,0.654526104976824,0.522664560603586,0.82930210809961,0.622874197598329,0.703930891737206,0.242459791379189,0.725141794871205,0.218375023220942,0.402749759520825,0.28091880157582,0.338353614690207,0.686143000291163,0.746371163673143,0.277165874751701,0.271133721764206,0.879319442034411,0.227507554611024,0.890521831755155,0.918101133889944,0.345621754045589,0.821347953287653,0.982385024406426,0.555909268413909,0.503546570785582,0.959625435820743,0.785471446611812,0.37548390507533,0.714714646461831,0.301695937821133,0.546835922768412,0.890022548915054,0.540137522656133,0.865409350019917,0.332921328753347,0.591899733158084,0.929658278115164,0.418035536059905,0.42608718604281,0.957896260615373,0.723695102916895,0.264676777427912,0.229162255411387,0.312977158443974,0.519495502944465,0.536670799511581,0.468932034578918,0.190605450341872,0.558930531080393,0.601894566245873,0.807055614557411,0.404816075763951,0.559619581019614,0.85258298271066,0.457021745490903,0.253268226095452,0.887458070403607,0.755708143855427,0.45622377551421,0.626502531277819,0.513084840686056,0.847591451113867,0.833630620426123,0.418025044206374,0.76558838134493,0.995680983509265,0.918789032449232,0.263399502328025,0.425286113586207,0.620838530317889,0.449439501937261,0.797932420403335,0.84482558532068,0.200975103192068,0.348331010936124,0.222342357828807,0.72188998001014,0.479105788645229,1,0.698556026718129,0.368302309415832,0.482353221192868,0.747201458813753,0.39532228988376,0.912647900861823,0.640134018324349,0.669627415888162,0.592494074194234,0.761330114525461,0.227287473694141,0.693490391410827,0.35595719992839,0.320995542107048,0.633656387361785,0.647709064214757,0.860263064000741,0.363308467879966,0.612979038877365,0.818638649336622,0.840971359182129,0.165503099546843,0.76822486756233,0.690662752371515,0.909682659929404,0.661077960566043,0.268594483436613,0.365727091939078,0.747094548606381,0.552688933066254,0.693594391953374,0.808150886259684,0.644570979662161,0.995810652025269,0.764709622033915,0.475218781977123,0.743276311425716,0.713563450978135,0.972292825402782,0.26520597557307,0.691186305602081,0.935287192179248,0.432354383178823,0.574942023213488,0.645721163874291,0.298512152711287,0.305821533773175,0.826197710964076,0.621148705068967,0.240856977767544,0.773593356073918,0.873328776156029,0.556130750355167,0.548710093321102,0.586098920245786,0.882939862083222,0.975771144572871,0.803658404291851,0.302936773764101,0.802057300173316,0.926627941416942,0.928584199621421,0.418398885448554,0.861751603164328,0.83736112114833,0.699095597637057,0.890995320687616,0.961348182602863,0.942426476608025,0.318202343859272,0.344721656606165,0.471822330591801,0.607309191088005,0.992501365651766,0.158693451208263,0.790059255442475,0.208983212866124,0.753089300283471,0.278524583148172,0.181396290311608,0.664671388603363,0.276499033215323,0.369155051335528,0.787465353390936,0.936737029487619,0.487086054306128,0.788459461712118,0.500437777790552,0.873479876682351,0.718015651602435,0.342965722184964,0.632617534058956,0.376250968037355,0.574892392255893,0.47985403762612,0.422008693217325],"y":[-0.439570033110703,0.62508735519206,-0.30825611011206,-0.451812079148881,-0.633195642644778,-0.693901170504899,-0.146107191877257,-0.565258911952534,-0.462159836390854,-0.949296443626697,-0.208467571526441,-0.526021221944991,-0.88312121428465,-0.325620001039572,-0.143452158235412,-0.473103647242579,-0.686724195884989,-0.823837193615416,-0.278348503669098,-0.767785818108784,-0.350302611280892,-0.513840137961094,-0.416638228729232,-0.0102169710978168,-0.264472933262127,-0.328932030254507,-0.455402104970477,-0.216932681535795,-0.384170531963377,-0.507048416091341,-0.382597701210671,-0.438017090611433,-0.29524356000735,-0.0474709798687954,-0.104341554116563,-0.402260000267431,-0.259706633287189,-0.752931565988398,-0.404446653539568,-0.606390205096062,-0.420977293323959,-0.789095480659103,-0.204948624384505,-0.200584845248123,-0.298145330701602,-0.946839694402208,-0.0237438790583648,-0.364465429397993,-0.51048828258946,-0.227147262893533,-0.257582438558247,-0.0977568513010639,-0.954538054643763,-0.5560187765212,-0.293465872209398,-0.86381940399474,-0.726098653538344,0.170667874832175,-0.179162872923387,-0.49525882397118,-0.533840250568365,-0.565147504572528,-0.490446755147395,-0.21886904590364,-0.363281332559465,-0.155896227393148,-0.729013164701432,-0.814905531450498,-0.617018855830565,-0.0784092486441967,-0.399852938724803,-0.579510192416585,-0.886269101805125,-0.321147309135159,-0.890582697003687,-0.641789251749255,-0.818450955630874,-0.171884592490196,-0.611476206376208,-0.55731040750332,0.0753326748299281,-0.646677024091212,-0.343348061573532,0.907139540411187,0.977011481507902,1,0.847267415748864,0.385630649854324,0.149712182403144,0.36634924055024,0.296645119798841,0.274814343355618,-0.222386160634219,-0.221752590625849,-0.490980127766365,-0.527563198780247,0.242272240484922,-0.178379631742018,0.00378483033501142,-0.793708747106507,-0.313763157751355,-0.690070838422886,0.307058949379089,0.167139570176351,-0.441505430358984,-0.365696191961741,-0.621066974736616,0.0850409047733471,-0.698685301068194,0.332771899399274,-0.0279531646343917,-0.458138316349024,-0.511193039010925,-0.8844288799077,-0.584585065366104,-0.878017141684901,0.267078335330761,-0.357316248853794,0.318223021639646,0.349867778296073,-0.186361839729558,-0.996544410235248,-0.0846516441284348,-0.044785358630248,-0.847439547845715,-0.137403183645599,-0.90349450399063,-0.0965447981736464,-0.026529506107873,-0.611645401836922,0.266466923830883,0.223740136899879,-0.928077691597584,-0.126256625298377,-0.828839378887561,-0.797628702326525,-0.0912272638600937,-0.00670960009801269,0.312880606841659,-0.597849314635411,-0.724666789656617,0.180889831675201,-0.808353920798349,0.388504872799172,-0.340754794709277,0.151577836274869,0.164188847950441,0.105812064568771,-0.728727583282789,0.13251186173599,-0.689583601808819,-0.142623471374939,-0.830533538625201,-0.167850331324705,-0.32475192555817,-0.253375035479805,-0.873377232111103,0.317074070694429,-0.91600580035585,-0.492632630101249,0.197998199456136,0.214124029728549,0.169730662436244,-0.171679889373688,-0.802183695423753,-0.854023505318619,-0.713252985080674,-0.253545000617021,0.332701142142429,-0.569625942112187,0.0101228651451168,-0.717476323624242,0.370227338261823,-0.537397226914426,-0.813794784993997,-0.877152593100188,-0.988949690308306,-0.431962155825692,-0.0229395106567032,-0.94811882084357,-0.442704730866662,-0.842058574245256,-0.351577962009184,0.104976258311949,-0.565852522334799,-0.900406503444178,-0.089446804183798,-0.495822002869996,0.0427454455885974,-0.00563246371487081,0.0207304263392498,-0.0890273143773056,-0.060484992067818,-0.586067422169032,-0.237520425763227,-0.802158044162906,-0.268041903427647,-0.675278965069562,-0.192348798031078,-0.744313894860934,0.0200474867283966,-0.162129051199604,-0.536479346927519,0.302886643191642,-0.918822396327496,-0.00174483210131315,-0.0963823814588983,-0.719421491022489,-0.772911983375303,-0.386580045169981,-0.984320814443315,0.0879949512610112,-0.976272722349332,-0.655968601386236,0.0823980972957863,-0.400435026504936,0.181314669157717,0.0964806682610342,-0.0830078624457662,-0.631457478443206,-0.924139179862867,-0.757815093666608,0.389154692422427,-0.750583713809243,-0.521253684678954,-0.819765345303142,-0.568631576804333,-0.320423858000844,-0.460030605236784,-0.632117937901046,0.228708486935743,-0.288976872470719,0.133324083249086,0.169035522797675,0.00405451803254064,-0.211206826472375,-0.315657050588328,0.239306027740169,0.172796210428381,-0.93321408401734,-0.62756181296187,-0.393101910965189,0.126321585395354,0.093172098621189,-0.710063138260564,-0.796718244799614,-0.115368654110598,0.0656813309677364,0.228899939414434,0.0104666708520185,0.0779490411540542,-0.664210751402206,0.0493581467145316,-1,0.265898164102332,-0.603874982045466,-0.464135381108251,0.0896136760034514,-0.71502171091369,-0.470101169601721,-0.9710282635304,0.252330849794826,0.213529370563591,-0.630391864046862]},"edges":{"from":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],"to":[67,48,46,68,28,30,20,73,9,22,31,65,12,21,72,59,52,8,18,39,74,40,55,7,34,53,4,82,5,58,77,43,32,19,37,66,54,51,29,25,50,56,71,78,63,70,24,41,47,36,17,76,16,23,62,49,6,45,80,57,81,60,61,26,10,15,75,38,27,35,33,79,83,64,42,69,11,3,14,44,13,86,85,58,81,84,87,146,241,257,208,92,48,28,238,112,242,30,116,118,236,182,180,124,132,121,206,103,9,102,120,131,91,22,159,160,229,162,154,231,133,148,125,93,8,262,139,192,140,173,195,252,74,213,214,172,217,55,253,152,193,119,117,4,210,183,144,151,190,149,255,168,221,240,43,247,96,239,122,201,220,141,19,251,136,261,186,167,37,202,171,129,54,207,258,29,137,25,145,113,90,127,100,94,215,212,1,71,107,123,115,78,234,95,184,105,174,204,197,101,142,223,254,216,155,177,211,263,98,97,256,166,264,109,36,138,114,128,130,191,99,260,165,23,170,147,110,156,222,181,80,161,237,230,169,81,203,235,60,26,126,179,15,164,178,27,194,205,243,157,150,259,79,225,153,143,187,248,232,176,175,108,83,228,226,196,224,88,245,135,244,69,89,106,249,219,246,11,233,189,198,250,158,199,218,188,185,104,134,227,163,200,209,111],"peso":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot","physics":false,"color":{"background":"#5DBAC3","border":"#01636D"}},"manipulation":{"enabled":false},"edges":{"smooth":false,"color":{"color":"grey","highlight":"#014D54"}},"physics":{"stabilization":false}},"groups":null,"width":null,"height":null,"idselection":{"enabled":false,"style":"width: 150px; height: 26px","useLabels":true,"main":"Select by id"},"byselection":{"enabled":false,"style":"width: 150px; height: 26px","multiple":false,"hideColor":"rgba(200,200,200,0.5)","highlight":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)","igraphlayout":{"type":"square"},"highlight":{"enabled":true,"hoverNearest":false,"degree":1,"algorithm":"all","hideColor":"rgba(200,200,200,0.5)","labelOnly":true},"collapse":{"enabled":false,"fit":false,"resetHighlight":true,"clusterOptions":null,"keepCoord":true,"labelSuffix":"(cluster)"}},"evals":[],"jsHooks":[]}</script>

]

.pull-right[

Se pueden hacer an√°lisis de grafos para desarrollar proyectos de Organizational Network Analysis.

En este sencillo ejemplo, estamos analizando las conecciones de LinkedIn de 3 profesores de People Analytics, para detectar los Data Scientists que tenemos en com√∫n. Este an√°lisis se puede usar para desarrollar un programa de referidos. ü§Ø

]

---
## Text Mining

Se puede analizar el texto de encuestas, curriculum vitaes, y opiniones de sitios como Glassdoor. Este es un ejemplo de una encuesta sobre Home Office del a√±o pasado.

.pull-left[
&lt;img src="humanosReales2021_files/figure-html/tm1-1.png" width="70%" /&gt;
]

.pull-right[
<div id="htmlwidget-8657982bd185f1da3157" style="width:75%;height:504px;" class="wordcloud2 html-widget"></div>
<script type="application/json" data-for="htmlwidget-8657982bd185f1da3157">{"x":{"word":["empresas","creo","productividad","muchas","teletrabajo","trabajar","modalidad","cuenta","forma","objetivos","puede","tener","casa","herramientas","oficina","situaci√≥n","costos","muchos","cambiar","empleado","equipo","manera","mayor","pandemia","personas","remoto","ten√≠an","trabajando","cambio","dar","demostrar","d√≠a","empresa","experiencia","formas","igual","lugar","mucho","necesario","necesidad","oportunidad","posible","resultados","ser","tareas","casos","conectados","cosas","cultura","dudas","empleador","exist√≠a","hacer","lado","lograr","mantener","mejor","metodolog√≠a","misma","mucha","posibilidad","procesos","recursos","seguir","trabaja","vamos","ver","vida"],"freq":[21,19,16,14,12,12,9,8,8,8,8,8,7,7,7,7,6,6,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],"fontFamily":"Segoe UI","fontWeight":"bold","color":["#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe","#4445f8","#7563fa","#9881fc","#b59ffe"],"minSize":0,"weightFactor":5.14285714285714,"backgroundColor":"white","gridSize":0,"minRotation":-0.785398163397448,"maxRotation":0.785398163397448,"shuffle":true,"rotateRatio":0.4,"shape":"circle","ellipticity":0.65,"figBase64":null,"hover":null},"evals":[],"jsHooks":{"render":[{"code":"function(el,x){\n                        console.log(123);\n                        if(!iii){\n                          window.location.reload();\n                          iii = False;\n\n                        }\n  }","data":null}]}}</script>

]

---
## Gr√°ficos

En R pod√©s hacer cualquier tipo de gr√°fico. 

&lt;img src="humanosReales2021_files/figure-html/plot1-1.png" width="33%" /&gt;&lt;img src="humanosReales2021_files/figure-html/plot1-2.png" width="33%" /&gt;&lt;img src="humanosReales2021_files/figure-html/plot1-3.png" width="33%" /&gt;


---
class: inverse, center, middle
# Literalmente,

--

### En R pod√©s hacer

--

### cualquier tipo de gr√°fico

---
## En serio... cualquier tipo de gr√°fico

Cr√©ditos: Ashten Anthony: [Guy checking out a girl meme](https://github.com/ashten28/my_ggplots/tree/master/guy_checking_out_a_girl_meme)


&lt;img src="humanosReales2021_files/figure-html/meme-1.png" width="504" /&gt;


---
# R es mucho m√°s que Estad√≠stica

R fue concebido como un lenguaje para an√°lisis estad√≠stico... pero hoy en d√≠a es mucho m√°s que eso. R tiene muchos paquetes y sus capacidades se han expandido tanto que puede hacer nuestro trabajo cotidiano mucho m√°s f√°cil.

--

En R pod√©s:

* Unir datos de m√∫ltiples fuentes ü§π

--

* Automatizar reportes con `R Markdown` üÜí

--

* Hacer presentaciones, como la que est√°s viendo, con el paquete `xaringan` üëç

--

* üíπ Hacer tableros de comando con el paquete `flexdashboard`.


--

* üë©‚Äçüé§ Compartir tu trabajo y hacerlo reproducible. 

--

* Escribir libros üìñ, crear blogs üóØ... y mucho m√°s

---
class: inverse middle center
# üîÆ An√°lisis Predictivos

---
# An√°lisis Predictivos
## An√°lisis predictivo de Rotaci√≥n de Personal

Los an√°lisis predictivos son una de las cosas m√°s potentes que podemos hacer en Analytics, porque nos permite gestionar de cara hacia el futuro.

--

Hay varios tipos de an√°lisis predictivos, hoy en particular nos vamos a centrar en uno para calcular probabilidades usando **regresi√≥n log√≠stica**.

--

El ejemplo de hoy, lo vamos a usar reciclando un caso de estudio que desarrollamos en Data 4HR en Python, y lo vamos a replicar en R. El caso original lo pueden ver en [este link](https://drive.google.com/file/d/1XcgT0_ovihpYtnqbEDhwu4zjwI4ltx1w/view?usp=sharing) y este es el [repositorio original](https://github.com/mlambolla/Analytics_HR_Attrition) (aprovechen para ver las diferencias en las sintaxis entre R y Python si pueden).


---
# ¬øDe qu√© hablamos cuando hablamos de an√°lisis predictivo?

--

El objetivo de los an√°lisis predictivos es detectar patrones, en nuestro caso, patrones en los comportamientos, en las caracter√≠sticas, y en los datos de los empleados para poder detectar qui√©n tiene m√°s probabilidad de renunciar por ejemplo.

--

Hoy, sin ning√∫n an√°lisis hecho, lo que sabemos de cada empleado es que tiene tanta probabilidad de renunciar, como de no renunciar. O sea que la cosa esta *"fifty-fifty"*, o para ir nerdeando la cosa, con una probabilidad de 0.5.

--

Lo que buscamos con un an√°lisis predictivo es mejorar esa probabilidad.

---

# ¬øQu√© es hacer un an√°lisis predictivo?

Hacer un an√°lisis no implica acertar el 100% de los casos, sino que es un intento de tener una idea de qui√©nes tienen m√°s **probabilidad** de irse. ¬øEsto quiere decir que alguien que tiene alta probabilidad de renunciar y no lo hace (o viceversa) el modelo est√° mal?

No. Al menos no necesariamente. ¬øQu√© es la probabilidad?

---

## Probabilidad

La probabilidad es toda una rama de la estad√≠stica en s√≠ misma. Se enfoca en intentar descubrir la certeza (o incertidumbre) de que ocurran las cosas. El resultado de una probabilidad siempre va a dar entre 0 y 1.

--

* Un resultado igual o cercano a **0** implica un evento improbable.

--

* Un resultado igual o cercano a **1** implica una alta probabilidad.

--

¬øQu√© pasa si ocurre algo improbable, o no ocurre algo con alta probabilidad? Es parte del margen de error inherente a la estad√≠stica, y por eso se asume que va a haber errores. El punto es, si repetimos el experimento 100 veces, ¬øcu√°nto acierta el modelo, y con qu√© precisi√≥n?

---

# ¬øC√≥mo se hace un an√°lisis predictivo?

Para hacer an√°lisis predictivos vamos a trabajar con datos del pasado. Tradicionalmente se usa una el 70% de los datos para *entrenar el modelo*, y el 30% de los datos, se los usa para *testear el modelo*. A estos datasets los vamos a llamar **training** y **test** respectivamente.

--

&lt;img src="https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/bbb2a548-6dba-4d9f-a4f7-8f20d13422e0.png" align='center' /&gt;

--

La selecci√≥n de los datos se hace al azar. As√≠ que hay que asegurarse que la proporci√≥n de renuncias sea similar en ambos datasets.

---

## ¬øPor qu√© trabajamos con el pasado?

En los ciclos de vida de los proyectos de data mining en general, est√° establecida como metodolog√≠a, la metodolog√≠a **CRISP-DM** (*Cross Industry Standard Process for Data Mining*). En donde:

.pull-left[
Entre la etapa de *Modelado* y la *Puesta en producci√≥n* (deployment) hay una etapa de evaluaci√≥n. Mientras dise√±amos el modelo, trabajamos con datos hist√≥ricos, en la etapa de *Evaluaci√≥n* vamos probando la precisi√≥n del modelo con datos nuevos, y si todo va bien, se pon√© en producci√≥n.
]

.pull-right[
&lt;img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/800px-CRISP-DM_Process_Diagram.png' width="55%" align="left" /&gt;
]

---

# Etapas de un modelo predictivo

Los pasos b√°sicos de un an√°lisis predictivo son:

* Definir la variable *target*
--

* Controlar los sesgos de los datos
--

* Explorar los datos
--

* Separar el dataset en **training** y **test**
--

* Correr el modelo
--

* Controlar los resultados
--

* Ajustar y repetir

---
# Nuestro primer modelo predictivo de attrition
## Regresi√≥n Log√≠stica

La regresi√≥n log√≠stica, a diferencia de la regresi√≥n lineal, en vez de arrojar un valor como resultado (un sueldo, un nivel de satisfacci√≥n), arroja una *probabilidad*, es decir que el resultado estar√° entre uno y cero.

--
&lt;br&gt;&lt;br&gt;
&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png" /&gt;

---

# Nuestro primer modelo predictivo de attrition
## Los datos

Vamos a usar un dataset *"de juguete"* para facilitar las cosas. El dataset s√≥lo tiene datos *num√©ricos* y *character* y no tiene datos faltantes.


```r
library(readr)
library(tidyverse)

datos_rh &lt;- read_csv("https://raw.githubusercontent.com/mlambolla/Analytics_HR_Attrition/master/HR_comma_sep.csv")
```

---
## Los datos


```r
glimpse(datos_rh)
```

```
## Rows: 14,999
## Columns: 10
## $ satisfaction_level    &lt;dbl&gt; 0.38, 0.80, 0.11, 0.72, 0.37, 0.41, 0.10, 0.92, ~
## $ last_evaluation       &lt;dbl&gt; 0.53, 0.86, 0.88, 0.87, 0.52, 0.50, 0.77, 0.85, ~
## $ number_project        &lt;dbl&gt; 2, 5, 7, 5, 2, 2, 6, 5, 5, 2, 2, 6, 4, 2, 2, 2, ~
## $ average_montly_hours  &lt;dbl&gt; 157, 262, 272, 223, 159, 153, 247, 259, 224, 142~
## $ time_spend_company    &lt;dbl&gt; 3, 6, 4, 5, 3, 3, 4, 5, 5, 3, 3, 4, 5, 3, 3, 3, ~
## $ Work_accident         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ left                  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ promotion_last_5years &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ sales                 &lt;chr&gt; "sales", "sales", "sales", "sales", "sales", "sa~
## $ salary                &lt;chr&gt; "low", "medium", "medium", "low", "low", "low", ~
```

---
## Los datos

Controlamos si hay datos nulos.

```r
any(is.na(datos_rh)) # Para verificar si hay alg√∫n dato faltante.
```

```
## [1] FALSE
```

```r
# Elminamos la variable 'sales' y cambiemos los valores de 'salary' a num√©ricos.
datos_rh &lt;- datos_rh %&gt;% 
  select(-sales) %&gt;%                      # Elimina columna 'sales'
  mutate(salary = as.numeric(case_when(   # Sobrescribe la columna salary reemplazando los valores por n√∫meros
    salary == 'low' ~ 0,                  # Cuando la variable es 'low' ahora es 0
    salary == 'medium' ~ 1,
    salary == 'high' ~ 2
  )))
```

---
## La variable target

Usualmente, en los modelos predictivos, tenemos una *variable objetivo* a la que llamamos **target**.

Por lo general usamos o una variable num√©rica o l√≥gica (`TRUE` o `FALSE`) codificada con `1` o `0`. Es una pr√°ctica com√∫n usar el n√∫mero 1 para lo que nos interesa saber, en nuestro caso, si la persona de nuestra base de datos, se fue de la compa√±√≠a. En nuestro caso, la variable *target* es la columna *left*. Veamos en los datos, cuantos empleados se fueron, y cu√°ntos a√∫n permanecen en la compa√±√≠a.


```r
datos_rh %&gt;% 
  count(left)
```

```
## # A tibble: 2 x 2
##    left     n
##   &lt;dbl&gt; &lt;int&gt;
## 1     0 11428
## 2     1  3571
```

&lt;br&gt;
Durante la sesi√≥n de hoy vamos a omitir todo el an√°lisis exploratorio, as√≠ nos enfocamos en toda la parte del modelo. En la vida real esto **tiene que estar**, as√≠ que lo dejamos como desaf√≠o para esta semana.

---
## La selecci√≥n de los datos de training y test

La selecci√≥n de los datos se hace al azar para construir los datasets de training y de test. O sea que cada vez que corramos todo el script, R va a elegir datos distintos.

As√≠ que una forma de elegir datos al azar, pero que sean siempre los mismos es con la funci√≥n `set.seed(234)`. Le pueden poner el n√∫mero que se les ocurra dentro de la funci√≥n.


```r
set.seed(234)
```

---

## La selecci√≥n de los datos de training y test

Para dividir el dataset vamos a usar el paquete `caret`. 


```r
library(caret)

set.seed(234)
*modelo_hr &lt;- createDataPartition(y = datos_rh$left,
*                                p = 0.7,
*                                list = FALSE)
```

Analicemos la funci√≥n `createDataPartition` y sus par√°metros:

* **y** representa a la variable *target*. F√≠jense que la selecci√≥n es usando la estructura *nombre_dataframe$nombre_variable_target*.
* **p** es el par√°metro para seleccionar el porcentaje de datos que vamos a seleccionar para el training set.
* **list = FALSE** evita que el nuevo objeto sea del tipo **lista**.

Esta funci√≥n crea un objeto con un √≠ndice de todas las filas seleccionadas para los datos de training. Con estos datos de muestra le vamos a pedir al algoritmo que analice los patrones para predecir las renuncias.

&gt; Prueben correr esta funci√≥n con un set.seed() diferente para ver qu√© selecciones distintas hubo.

---
## La selecci√≥n de los datos de training y test


.pull-left[Ahora creamos los dos datasets


```r
#Armo el dataframe de training [fila, columna]
modelo_hr_train &lt;- datos_rh[modelo_hr,]

# Con el signo - (menos), creamos el dataset de testing, con todas las filas 'que no est√©n en modelo_hr'
modelo_hr_test &lt;- datos_rh[-modelo_hr,]
```

]


.pull-right[Es una buena pr√°ctica chequear que las proporciones de bajas (nuestra variable target) sean similares tanto en training como en test.


```r
modelo_hr_train %&gt;%
  summarise(turnover = mean(left))
```

```
## # A tibble: 1 x 1
##   turnover
##      &lt;dbl&gt;
## 1    0.237
```

```r
modelo_hr_test %&gt;%
  summarise(turnover = mean(left))
```

```
## # A tibble: 1 x 1
##   turnover
##      &lt;dbl&gt;
## 1    0.240
```

Todo en orden, avancemos.
]

---

## Entrenando el modelo

El primer paso es generar un modelo predictivo con los datos de *training*. *Left* es la variable objetivo, y los s√≠mbolos `~ .` significa que el resto del dataset son las variables explicatorias, con excepci√≥n de *department* que la sacamos de los c√°lculos.


```r
# Calculamos un modelo de entrenamiento, sacando department de los c√°lculos.
*modelo_glm2 &lt;- glm(left ~. , family = "binomial",
*                  data = modelo_hr_train)
```

---


```r
summary(modelo_glm2)
```

```
## 
## Call:
## glm(formula = left ~ ., family = "binomial", data = modelo_hr_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1513  -0.6557  -0.4045  -0.1291   3.1322  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)            0.4773770  0.1427456   3.344 0.000825 ***
## satisfaction_level    -4.2030660  0.1177452 -35.696  &lt; 2e-16 ***
## last_evaluation        0.8969245  0.1776465   5.049 4.44e-07 ***
## number_project        -0.3124774  0.0254747 -12.266  &lt; 2e-16 ***
## average_montly_hours   0.0040675  0.0006174   6.588 4.46e-11 ***
## time_spend_company     0.2644284  0.0182917  14.456  &lt; 2e-16 ***
## Work_accident         -1.5487618  0.1070295 -14.470  &lt; 2e-16 ***
## promotion_last_5years -1.4740251  0.3099927  -4.755 1.98e-06 ***
## salary                -0.7144916  0.0452392 -15.794  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11510.1  on 10499  degrees of freedom
## Residual deviance:  9003.8  on 10491  degrees of freedom
## AIC: 9021.8
## 
## Number of Fisher Scoring iterations: 5
```

---

### Chequeando multicolinealidad

En este tipo de modelos, vamos a buscar variables que est√©n relacionadas, pero de manera independientemente, sin colinealidad.

Si hay colinealidad entre dos variables puede ocurrir porque una variable est√° construida a partir de otra variable, lo que implica que las variables colineales son de alguna manera, dos expresiones de la misma cosa, o bien, que una variable est√© construida a partir de la otra (ejemplos: el √≠ndica de masa muscular, un bono de antig√ºedad, etc.)

Una forma de detectar esto es a trav√©s de la funci√≥n `vif` (Variance Inflation Factor):

```r
library(car)

vif(modelo_glm2)
```

```
##    satisfaction_level       last_evaluation        number_project 
##              1.167285              1.434725              1.778566 
##  average_montly_hours    time_spend_company         Work_accident 
##              1.518708              1.106536              1.011603 
## promotion_last_5years                salary 
##              1.014474              1.027210
```


---

### Chequando multicolinealidad

Para tener en cuenta, tenemos que buscar variables con VIF &gt; 5. Si esto ocurriera, tendr√≠amos que correr los modelos, eliminando estas variables, hasta tener un modelo en el que todas las variables tengan un VIF menor a 5.

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; VIF &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Interpretacion &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; No hay colinealidad &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Entre 1 y 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Moderadamente colineales &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 o m√°s &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Colinealidad alta &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Estimando probabilidades

Una vez que tenemos un modelo "entrenado" podemos estimar las probabilidades para los sets de training y de test.


```r
pred_train &lt;- predict(modelo_glm2, newdata = modelo_hr_train, type = "response")
```

Luego, lo repetimos la predicci√≥n para los datos de test. Lo que obtenemos es un gran listado de probabilidades (asegurarse que los resultados est√©n entre 0 y 1).


```r
*pred_test &lt;- predict(modelo_glm2, newdata = modelo_hr_test, type = "response")

pred_test[1:20]
```

```
##          1          2          3          4          5          6          7 
## 0.51663753 0.15504718 0.50443723 0.36837721 0.04069019 0.24150483 0.50847796 
##          8          9         10         11         12         13         14 
## 0.73766930 0.68739109 0.17815363 0.46452635 0.50693990 0.73132128 0.77264152 
##         15         16         17         18         19         20 
## 0.56410797 0.65348778 0.36755979 0.04007765 0.15053564 0.02813936
```

---

## Matriz de Confusi√≥n

Como primer paso tenemos que a√±adir las probabilidades del objeto *pred_test* al dataframe de testing.


```r
# Asigna las probabilidades a una variable nueva llamada "score".
modelo_hr_test$score &lt;- pred_test

# Luego en base al score, asigno una clase predicha en funci√≥n a si la probabilidad es mayor a 0.5
modelo_hr_test &lt;- modelo_hr_test %&gt;% 
* mutate(prediccion = ifelse(score &gt; 0.5, 1, 0))
```

&lt;table class="table table-striped" style="font-size: 11px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; satisfaction_level &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; last_evaluation &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; number_project &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; average_montly_hours &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; time_spend_company &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Work_accident &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; left &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; promotion_last_5years &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; salary &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; score &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; prediccion &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.11 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 272 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5166375 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 224 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1550472 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.55 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 148 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5044372 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.78 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.99 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 255 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3683772 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Matriz de Confusi√≥n

La matriz de confusi√≥n es una tabla de doble entrada en donde lo que hacemos es contrastar los aciertos del modelo, contra los fallos.

&lt;img src="https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg" width="67%"/&gt;

---

## Matriz de Confusi√≥n

Construyamos una matriz de confusi√≥n b√°sica del modelo de testing.


```r
conf_matrix &lt;- table(modelo_hr_test$left, modelo_hr_test$prediccion)
conf_matrix
```

```
##    
##        0    1
##   0 3140  281
##   1  694  384
```

En esta matriz vemos que en 3.140 casos, el modelo acert√≥ a empleados que no se fueron, y que acert√≥ en 384 predicciones de empleados que renunciaron. Veamos otras m√©tricas que podemos sacar.

---

## Matriz de Confusi√≥n

Para ver otras m√©tricas posibles de la matriz de confusi√≥n vamos a usar la funci√≥n `confusionMatrix` del paquete `caret`.

---


```r
confusionMatrix(conf_matrix)
```

```
## Confusion Matrix and Statistics
## 
##    
##        0    1
##   0 3140  281
##   1  694  384
##                                          
##                Accuracy : 0.7833         
##                  95% CI : (0.771, 0.7952)
##     No Information Rate : 0.8522         
##     P-Value [Acc &gt; NIR] : 1              
##                                          
##                   Kappa : 0.3155         
##                                          
##  Mcnemar's Test P-Value : &lt;2e-16         
##                                          
##             Sensitivity : 0.8190         
##             Specificity : 0.5774         
##          Pos Pred Value : 0.9179         
##          Neg Pred Value : 0.3562         
##              Prevalence : 0.8522         
##          Detection Rate : 0.6979         
##    Detection Prevalence : 0.7604         
##       Balanced Accuracy : 0.6982         
##                                          
##        'Positive' Class : 0              
## 
```


---

## Curva ROC

La **curva ROC**, es una forma visual de calcular el **AUC** (*Area Under the Curve*, el √°rea bajo la curva). Internamente lo que hace este gr√°fico es ordenar las probabilidades de mayor a menor, y a medida que tenemos un *positivo verdadero* (el empleado se fue y nosotros predecimos que se iba) la curva se mueve hacia arriba. Con cada falso positivo, la curva se va moviendo a la derecha.

Para esto vamos a usar la librer√≠a `pROC`.

&gt; Video: c√≥mo se construye la curva ROC: [https://youtu.be/OjWew7W4KnY](https://youtu.be/OjWew7W4KnY)

---

## AUC - Area Under the Curve

Una m√©trica complementaria de la *curva ROC* es el **√Årea Bajo la Curva** (AUC, por sus siglas en ingl√©s) que refleja la proporci√≥n del espacio que hay debajo de la curva ROC en el gr√°fico.

&lt;img src="https://miro.medium.com/max/1175/1*2nd7NTEBosPakccmLVWy9A.png", width="45%" /&gt;

---

## AUC - Area Under the Curve

Usaremos otra librer√≠a para graficar al mismo tiempo la curva ROC, y calcular el AUC.


```r
library(pROC)

pROC_obj &lt;- roc(modelo_hr_test$left, modelo_hr_test$score,
                smoothed = FALSE,
                # argumentos del intervalo de confianza
                ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                # argumentos del gr√°fico
                plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                print.auc=TRUE, show.thres=TRUE)
```

---
&lt;img src="humanosReales2021_files/figure-html/unnamed-chunk-19-1.png" width="504" /&gt;
---

class: inverse, center, middle

&lt;img src="https://complementarytraining.net/wp-content/uploads/2014/07/quote-essentially-all-models-are-wrong-but-some-are-useful-george-e-p-box-212711.jpg", width="90%" /&gt;

---
class: inverse, center, middle

# ¬øQu√© tan bueno es el modelo?

---
## "Todos los empleados son iguales pero hay empleados m√°s iguales que otros"

.pull-left[
Algo interesante que surge del an√°lisis exploratorio, son los tres grupos notorios que tenemos entre los empleados que se van.

Tenemos un grupo llamativo, que representan a los empleados de *alto desempe√±o* y de *alto nivel de satisfacci√≥n*.


```r
ggplot(modelo_hr_test, aes(x = last_evaluation, y = satisfaction_level, color = factor(left)))+
  geom_point(alpha = 0.8)+
  scale_color_manual(values = c("#BFC9CA","#2874A6"))
```


]

.pull-right[
&lt;img src="humanosReales2021_files/figure-html/unnamed-chunk-20-1.png" width="80%" /&gt;
]

---

class: center, middle

## ¬øQu√© tan bueno es el modelo con los top de lo top?


&lt;img src="https://mott.pe/noticias/wp-content/uploads/2016/02/Qu%C3%A9-le-preguntar%C3%ADas-a-Homero-Simpson-de-darse-la-oportunidad-portada.png" /&gt;

---

## ¬øQu√© tan bueno es el modelo con los top de lo top?

.pull-left[

```r
# Seleccionamos las variables para elegir los clusters
variables_cluster &lt;- modelo_hr_test %&gt;%
  select(last_evaluation, satisfaction_level)

# Preparo los datos para hacer el c√°lculo
vc &lt;- scale(variables_cluster)

# Corro el algoritmo de clustering
set.seed(87)
fit_vc &lt;- kmeans(vc, 3)

# Agrego los clusters ajustados (calculados) al dataset
modelo_hr_test$cluster &lt;- fit_vc$cluster

library(ggthemes)
ggplot(modelo_hr_test, aes(x = last_evaluation, y = satisfaction_level, color = factor(cluster)))+
  geom_point(alpha = 0.8)+
  scale_color_colorblind()
```

]

.pull-right[
&lt;img src="humanosReales2021_files/figure-html/unnamed-chunk-21-1.png" width="504" /&gt;
]
---

## ¬øQu√© tan bueno es el modelo con los top de lo top?



```r
# Filtramos los datos del cluster 1
modelo_hr_c1 &lt;- modelo_hr_test %&gt;% 
  filter(cluster == 1)

conf_matrix_c1 &lt;- table(modelo_hr_c1$prediccion, modelo_hr_c1$left)
```

---

```r
# Veamos todas las m√©tricas de la matriz con esta funci√≥n del paquete caret
confusionMatrix(conf_matrix_c1)
```

```
## Confusion Matrix and Statistics
## 
##    
##        0    1
##   0 1642  290
##   1   25    4
##                                           
##                Accuracy : 0.8394          
##                  95% CI : (0.8224, 0.8554)
##     No Information Rate : 0.8501          
##     P-Value [Acc &gt; NIR] : 0.9121          
##                                           
##                   Kappa : -0.0022         
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.98500         
##             Specificity : 0.01361         
##          Pos Pred Value : 0.84990         
##          Neg Pred Value : 0.13793         
##              Prevalence : 0.85008         
##          Detection Rate : 0.83733         
##    Detection Prevalence : 0.98521         
##       Balanced Accuracy : 0.49930         
##                                           
##        'Positive' Class : 0               
## 
```

---

.pull-left[
.center[# Muchas gracias!]
&lt;img src="https://media.giphy.com/media/d68IdpvmAHohx5NMEV/giphy.gif" /&gt;
]

.pull-right[
Si te gust√≥ esta sesi√≥n me pueden encontrar en:

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:blue;overflow:visible;position:relative;"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> [Sergio Garcia Mora](https://www.linkedin.com/in/sergiogarciamora/)
<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:blue;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> [@sergiogarciamor](https://twitter.com/sergiogarciamor)
<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:blue;overflow:visible;position:relative;"><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg> [Telegram](https://t.me/SergioGarciaMora)
<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:blue;overflow:visible;position:relative;"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg> [sergio@d4hr.com](mailto:sergio@d4hr.com)

Recuerden compartir sus capturas de pantalla y sensaciones con los hashtags:

* #### #R4HR
* #### #data4hr
* #### #PeopleAnalytics
* #### #RStats_ES
* #### #BetterWithData
]
---
background-color: #F0B27A
class: inverse, center, middle

## Seguir al Club de R para RRHH en nuestras redes

### [link.tree/r4hrclub](https://www.linktr.ee/r4hrclub) üì°
&lt;img src="https://media.giphy.com/media/93fsZ7rI488L908x0T/giphy.gif" width="30%" /&gt;


---
# Fuentes de Consulta

Max Kuhn, Libro: [The caret package](https://topepo.github.io/caret/index.html)

Pablo Casas, Libro [Libro Vivo de Ciencia de Datos](https://librovivodecienciadedatos.ai/)



### Regresi√≥n log√≠stica
https://rpubs.com/Joaquin_AR/229736
https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple


### Curvas ROC
https://rviews.rstudio.com/2019/03/01/some-r-packages-for-roc-curves/

---

# Paquetes utilizados

* [ggplot2](https://ggplot2.tidyverse.org): H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.
* [tidyverse](https://doi.org/10.21105/joss.01686): Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686
* [funModeling](https://CRAN.R-project.org/package=funModeling): Pablo Casas (2020). funModeling: Exploratory Data Analysis and Data Preparation Tool-Box. R package version 1.9.4.
* [lubridate](http://www.jstatsoft.org/v40/i03/): Garrett Grolemund, Hadley Wickham (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25.
* [ggthemes](https://CRAN.R-project.org/package=ggthemes): Jeffrey B. Arnold (2019). ggthemes: Extra Themes, Scales and Geoms for 'ggplot2'. R package version 4.2.0.
* [gargle](https://CRAN.R-project.org/package=gargle): Jennifer Bryan, Craig Citro and Hadley Wickham (2020). gargle: Utilities for Working with
  Google APIs. R package version 0.5.0.
* [googlesheets4](https://CRAN.R-project.org/package=googlesheets4): Jennifer Bryan (2020). googlesheets4: Access Google Sheets using the Sheets API V4. R package version 0.2.0.
* [caret](https://CRAN.R-project.org/package=caret): Max Kuhn (2020). caret: Classification and Regression Training. R package version 6.0-86.


---
background-color: #CACFD2
class: center, bottom

# <svg aria-hidden="true" role="img" viewBox="0 0 480 512" style="height:1em;width:0.94em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:black;overflow:visible;position:relative;"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
[Repo](https://github.com/chechoid/humanosReales)


Presentaci√≥n realizada con el paquete [Xaringan](https://github.com/yihui/xaringan) desarrollado por Yihui Xie.

Gracias a [Patricia Loto](https://twitter.com/patriloto) por compartir el [tutorial](https://twitter.com/patriloto/status/1260822644590608391?s=20)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "191:100",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
